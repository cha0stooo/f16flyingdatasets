{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lagrange_net",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cha0stooo/f16flyingdatasets/blob/master/lagrange_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a7QW3FJQ7cn",
        "outputId": "40ca438a-0e67-41db-90c9-19e316401bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!ls -R\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".:\n",
            "f16flyingdatasets  sample_data\n",
            "\n",
            "./f16flyingdatasets:\n",
            "state_pitch2020-9-16.dat  state_roll2020-9-16.dat  state_yaw2020-9-16.dat\n",
            "state_pitch2020-9-25.dat  state_roll2020-9-25.dat  state_yaw2020-9-25.dat\n",
            "\n",
            "./sample_data:\n",
            "anscombe.json\t\t      mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X3O5JS3LqpZ",
        "outputId": "975e49ac-c0c9-4162-db30-8735de726a9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense,BatchNormalization\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "class MyModel(Model):\n",
        "  def __init__(self,layers):  \n",
        "    super(MyModel, self).__init__()\n",
        "    tf.keras.backend.set_floatx(\"float64\")  \n",
        "    self.layer_list = []\n",
        "    self.bn = []\n",
        "    \n",
        "    for width in layers[1:-2]:\n",
        "        self.layer_list.append(Dense(width, activation='relu',kernel_initializer= tf.initializers.he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "        self.bn.append(BatchNormalization())\n",
        "    \n",
        "    #self.layer_list.append(Dense(layers[-1], activation='linear',kernel_initializer= tf.initializers.normal()))        \n",
        "    self.Lo_layer = Dense(layers[-2],activation='linear',kernel_initializer= 'glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "    self.Ld_layer = Dense(layers[-1],activation='relu',kernel_initializer= tf.initializers.he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "     #定义一个ld的偏置\n",
        "    self.bias_d = []\n",
        "    bias_d = tf.random.normal([1,3],dtype = tf.float64)\n",
        "    self.bias_d.append(tf.Variable(bias_d, dtype=tf.float64, trainable=True))\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x):\n",
        "    for index in range(len(self.layer_list)):\n",
        "      x = self.layer_list[index](x)\n",
        "      x = self.bn[index](x)\n",
        "        \n",
        "    lo = self.Lo_layer(x)\n",
        "    ld = self.Ld_layer(x)+self.bias_d[0]\n",
        "    \n",
        "    return lo,ld\n",
        "    \n",
        "def save_model(model,path):\n",
        "  #保存模型参数\n",
        "  checkpoint = tf.train.Checkpoint(myModel=model)\n",
        "  checkpoint.save(path+'/model.ckpt')\n",
        "    \n",
        "def restore_model(model,path):\n",
        "  #恢复模型参数\n",
        "  checkpoint = tf.train.Checkpoint(myModel=model)\n",
        "  checkpoint.restore(tf.train.latest_checkpoint(path))\n",
        "\n",
        "#产生飞行器训练数据\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "\n",
        "class vehicle_net():\n",
        "  def __init__(self,layers,hp):\n",
        "    self.epochs = hp[\"epochs\"]\n",
        "    self.tf_optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=hp[\"tf_lr\"],\n",
        "        beta_1=hp[\"tf_b1\"],\n",
        "        epsilon=hp[\"tf_eps\"])\n",
        "    self.LAM = hp[\"lamda\"]\n",
        "    #batchsize = hp['batchsize']\n",
        "    self.model = MyModel(layers=layers)\n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def cal_inverse_dynamic(self,q,dq,ddq):\n",
        "    q = tf.convert_to_tensor(q)\n",
        "    dq = tf.convert_to_tensor(dq)   \n",
        "    dq = tf.reshape(dq,[dq.shape[0],dq.shape[1],1])  #NX3 -> NX3X1\n",
        "    ddq = tf.convert_to_tensor(ddq)\n",
        "    ddq = tf.reshape(ddq,[ddq.shape[0],ddq.shape[1],1])  #NX3 -> NX3X1\n",
        "    sample_num = q.shape[0]\n",
        "    with tf.GradientTape(persistent=True) as tp:\n",
        "      tp.watch(q) \n",
        "      Y_lo,Y_ld = self.model(q)   \n",
        "      l1 = Y_ld[:,0:1]\n",
        "      l2 = Y_ld[:,1:2]\n",
        "      l3 = Y_ld[:,2:3]\n",
        "      l4 = Y_lo[:,0:1]\n",
        "      l5 = Y_lo[:,1:2]\n",
        "      l6 = Y_lo[:,2:3]\n",
        "      # #计算dLi_dq\n",
        "      dL1_dq = tp.gradient(l1,q)  #NX3\n",
        "      dL2_dq = tp.gradient(l2,q)  #NX3\n",
        "      dL3_dq = tp.gradient(l3,q)  #NX3\n",
        "      dL4_dq = tp.gradient(l4,q)  #NX3\n",
        "      dL5_dq = tp.gradient(l5,q)  #NX3\n",
        "      dL6_dq = tp.gradient(l6,q)  #NX3\n",
        "      #计算dl_dqi\n",
        "      dLd_dq1 = tf.stack([dL1_dq[:,0:1],dL2_dq[:,0:1],dL3_dq[:,0:1]],axis=1)  #NX3X1\n",
        "      dLd_dq1 = tf.squeeze(dLd_dq1,axis=2)  #NX3\n",
        "      dLd_dq2 = tf.stack([dL1_dq[:,1:2],dL2_dq[:,1:2],dL3_dq[:,1:2]],axis=1)\n",
        "      dLd_dq2 = tf.squeeze(dLd_dq2,axis=2)  #NX3  \n",
        "      dLd_dq3 = tf.stack([dL1_dq[:,2:3],dL2_dq[:,2:3],dL3_dq[:,2:3]],axis=1)\n",
        "      dLd_dq3 = tf.squeeze(dLd_dq3,axis=2)  #NX3  \n",
        "      dLo_dq1 = tf.stack([dL4_dq[:,0:1],dL5_dq[:,0:1],dL6_dq[:,0:1]],axis=1)\n",
        "      dLo_dq1 = tf.squeeze(dLo_dq1,axis=2)  #NX3  \n",
        "      dLo_dq2 = tf.stack([dL4_dq[:,1:2],dL5_dq[:,1:2],dL6_dq[:,1:2]],axis=1)  \n",
        "      dLo_dq2 = tf.squeeze(dLo_dq2,axis=2)  #NX3\n",
        "      dLo_dq3 = tf.stack([dL4_dq[:,2:3],dL5_dq[:,2:3],dL6_dq[:,2:3]],axis=1)  \n",
        "      dLo_dq3 = tf.squeeze(dLo_dq3,axis=2)  #NX3\n",
        "    del tp\n",
        "    #计算逆动力学方程中的各项：M = J*ddq-0.5*[dq_T*(dl_dq1*L_T+L*dL_dq1_T)*dq ...]+dJ*dq\n",
        "    #1.J = L*L'\n",
        "    L_mat,L_mat_T,J = self.cal_J(Y_lo,Y_ld)\n",
        "    #2.dJ/dt = dLdt@L'+L@dL'dt = dLdt@L'+L@dLdt'\n",
        "    dL1_dq = tf.reshape(dL1_dq,[dL1_dq.shape[0],1,dL1_dq.shape[1]])\n",
        "    dL2_dq = tf.reshape(dL2_dq,[dL2_dq.shape[0],1,dL2_dq.shape[1]])\n",
        "    dL3_dq = tf.reshape(dL3_dq,[dL3_dq.shape[0],1,dL3_dq.shape[1]])\n",
        "    dL4_dq = tf.reshape(dL4_dq,[dL4_dq.shape[0],1,dL4_dq.shape[1]])\n",
        "    dL5_dq = tf.reshape(dL5_dq,[dL5_dq.shape[0],1,dL5_dq.shape[1]])\n",
        "    dL6_dq = tf.reshape(dL6_dq,[dL6_dq.shape[0],1,dL6_dq.shape[1]])\n",
        "    dl11 = tf.squeeze(dL1_dq@dq,axis=2)   #NX1X1 -> NX1\n",
        "    dl22 = tf.squeeze(dL2_dq@dq,axis=2)\n",
        "    dl33 = tf.squeeze(dL3_dq@dq,axis=2)\n",
        "    dl21 = tf.squeeze(dL4_dq@dq,axis=2)\n",
        "    dl31 = tf.squeeze(dL5_dq@dq,axis=2)\n",
        "    dl32 = tf.squeeze(dL6_dq@dq,axis=2)\n",
        "    dl12 = tf.zeros((dl11.shape[0],1),dtype = tf.float64)\n",
        "    dl13 = tf.zeros((dl11.shape[0],1),dtype = tf.float64)\n",
        "    dl23 = tf.zeros((dl11.shape[0],1),dtype = tf.float64)\n",
        "    dl = tf.stack([dl11,dl12,dl13,dl21,dl22,dl23,dl31,dl32,dl33],axis=1)\n",
        "    dl = tf.squeeze(dl,axis=2)\n",
        "    dl_mat = tf.reshape(dl,[dl.shape[0],3,3])\n",
        "    dl_mat_T = tf.transpose(dl_mat,perm=[0,2,1])  #将NX3X3 中第二维和第三维进行转置 \n",
        "    dJ = dl_mat@L_mat_T+L_mat@dl_mat_T\n",
        "    #3.(dq'@J@dq)/dq\n",
        "    #dLo_dq1 = dY_lo[:,:,0]     #NX3\n",
        "    #dLd_dq1 = dY_ld[:,:,0]\n",
        "    dl_dq1_mat = self.vec2mat(dLd_dq1,dLo_dq1)   #dl_dq1\n",
        "    # dLo_dq2 = dY_lo[:,:,1]\n",
        "    # dLd_dq2 = dY_ld[:,:,1]\n",
        "    dl_dq2_mat = self.vec2mat(dLd_dq2,dLo_dq2)\n",
        "    # dLo_dq3 = dY_lo[:,:,2]\n",
        "    # dLd_dq3 = dY_ld[:,:,2]\n",
        "    dl_dq3_mat = self.vec2mat(dLd_dq3,dLo_dq3)\n",
        "    #计算dq_T*(dl_dq1*L_T+L*dL_dq1_T)*dq\n",
        "    dq_T = tf.transpose(dq,perm=[0,2,1])    #NX3X1 ->NX1X3\n",
        "    tmp1 = dq_T@(dl_dq1_mat@L_mat_T+L_mat@tf.transpose(dl_dq1_mat,perm=[0,2,1]))@dq   #NX1X1\n",
        "    tmp2 = dq_T@(dl_dq2_mat@L_mat_T+L_mat@tf.transpose(dl_dq2_mat,perm=[0,2,1]))@dq   #NX1X1\n",
        "    tmp3 = dq_T@(dl_dq3_mat@L_mat_T+L_mat@tf.transpose(dl_dq3_mat,perm=[0,2,1]))@dq   #NX1X1\n",
        "    tmp = tf.stack([tmp1,tmp2,tmp3],axis=1)\n",
        "    tmp = tf.squeeze(tmp,axis=3)   #NX3X1X1  -> NX3X1\n",
        "    #-0.5*[dq_T*(dl_dq1*L_T+L*dL_dq1_T)*dq ...]   #NX3X1\n",
        "    f2 = -0.5*tmp\n",
        "    #4.计算M = J*ddq-0.5*[dq_T*(dl_dq1*L_T+L*dL_dq1_T)*dq ...]+dJ*dq\n",
        "    M_pre = J@ddq+f2+dJ@dq\n",
        "    gama,phi = q[:,0:1],q[:,1:2]\n",
        "    r11 = tf.ones_like(gama)\n",
        "    r12 = tf.zeros_like(gama)\n",
        "    r13 = -tf.sin(phi)\n",
        "    r21 = tf.zeros_like(gama)\n",
        "    r22 = tf.cos(gama)\n",
        "    r23 = tf.sin(gama)*tf.cos(phi)\n",
        "    r31 = tf.zeros_like(gama)\n",
        "    r32 = -tf.sin(gama)\n",
        "    r33 = tf.cos(gama)*tf.cos(phi)\n",
        "    R = tf.stack([r11,r12,r13,r21,r22,r23,r31,r32,r33],axis=1)\n",
        "    R = tf.squeeze(R,axis=2)\n",
        "    R = tf.reshape(R,[R.shape[0],3,3])\n",
        "    R_T = tf.transpose(R,perm=[0,2,1])  #将NX3X3 中第二维和第三维进行转置\n",
        "    M_pre = tf.linalg.inv(R_T)@M_pre\n",
        "    return M_pre    #NX3X1\n",
        "\n",
        "  @tf.function\n",
        "  def vec2mat(self,dLd_dq1,dLo_dq1):\n",
        "    #将N个3X1的dld_dqi 以及dlo_dqi 组合成 N个 3X3的矩阵\n",
        "    dl_dq11 = dLd_dq1[:,0:1]\n",
        "    dl_dq12 = tf.zeros((dl_dq11.shape[0],1),dtype = tf.float64)\n",
        "    dl_dq13 = tf.zeros((dl_dq11.shape[0],1),dtype = tf.float64)\n",
        "    dl_dq21 = dLo_dq1[:,0:1]\n",
        "    dl_dq22 = dLd_dq1[:,1:2]\n",
        "    dl_dq23 = tf.zeros((dl_dq11.shape[0],1),dtype = tf.float64)\n",
        "    dl_dq31 = dLo_dq1[:,1:2]\n",
        "    dl_dq32 = dLo_dq1[:,2:3]\n",
        "    dl_dq33 = dLd_dq1[:,2:3]\n",
        "    dl = tf.stack([dl_dq11,dl_dq12,dl_dq13,dl_dq21,dl_dq22,dl_dq23,dl_dq31,dl_dq32,dl_dq33],axis=1)\n",
        "    dl = tf.squeeze(dl,axis=2)\n",
        "    dl_dq_mat = tf.reshape(dl,[dl.shape[0],3,3])\n",
        "    return dl_dq_mat\n",
        "  @tf.function  \n",
        "  def cal_J(self,Lo,Ld): \n",
        "    l1 = Ld[:,0:1]\n",
        "    l2 = tf.zeros((l1.shape[0],1),dtype = tf.float64)\n",
        "    l3 = tf.zeros((l1.shape[0],1),dtype = tf.float64)\n",
        "    l4 = Lo[:,0:1]\n",
        "    l5 = Ld[:,1:2]\n",
        "    l6 = tf.zeros((l1.shape[0],1),dtype = tf.float64)\n",
        "    l7 = Lo[:,1:2]\n",
        "    l8 = Lo[:,2:3]\n",
        "    l9 = Ld[:,2:3]\n",
        "    L_vec = tf.stack([l1,l2,l3,l4,l5,l6,l7,l8,l9],axis=1)\n",
        "    L_vec = tf.squeeze(L_vec,axis=2)\n",
        "    L_mat = tf.reshape(L_vec,[L_vec.shape[0],3,3])\n",
        "    L_vec_T = tf.stack([l1,l4,l7,l2,l5,l8,l3,l6,l9],axis=1)\n",
        "    L_vec_T = tf.squeeze(L_vec_T,axis=2)\n",
        "    L_mat_T = tf.reshape(L_vec_T,[L_vec_T.shape[0],3,3])\n",
        "    J_mat = L_mat@L_mat_T\n",
        "    #J_vec_total = tf.reshape(J_mat,[J_mat.shape[0],9])\n",
        "    return L_mat,L_mat_T,J_mat  \n",
        "  @tf.function\n",
        "  def train(self,q,dq,ddq,mom0):\n",
        "    with tf.GradientTape() as tp:\n",
        "      M_pre0 = self.cal_inverse_dynamic(q,dq,ddq)\n",
        "      #M_pre = tf.squeeze(M_pre0,axis=2)\n",
        "      #四种计loss方式等价\n",
        "      #loss = (tf.keras.losses.MSE(M_pre[:,0],mom[:,0])\\\n",
        "          # +tf.keras.losses.MSE(M_pre[:,1],mom[:,1])\\\n",
        "          # +tf.keras.losses.MSE(M_pre[:,2],mom[:,2]))/3\n",
        "      #loss = tf.reduce_mean(tf.keras.losses.MSE(mom,M_pre))\n",
        "      res_loss = tf.reduce_mean(tf.keras.losses.MSE(mom0,M_pre0))\n",
        "      loss = res_loss#+LAM*self.model.get_l2_loss()\n",
        "      # loss0 = tf.norm(M_pre[:,0]-mom[:,0])**2/samp_num + \\\n",
        "      #     tf.norm(M_pre[:,1]-mom[:,1])**2/samp_num+\\\n",
        "      #         tf.norm(M_pre[:,2]-mom[:,2])**2/samp_num\n",
        "    variables = self.model.trainable_variables\n",
        "    grads = tp.gradient(loss,variables)\n",
        "    self.tf_optimizer.apply_gradients(grads_and_vars=zip(grads,variables))\n",
        "    del tp\n",
        "    #print(epoch,loss.numpy())\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def fit(self,q,dq,ddq,Mom,mini_batch_size=128):     \n",
        "    loss_save = []\n",
        "    N_data = q.shape[0]\n",
        "    for ep in range(self.epochs): \n",
        "      #idx_data = np.random.choice(N_data, min(mini_batch_size, N_data))\n",
        "      qi   = q#[idx_data,:]\n",
        "      dqi  = dq#[idx_data,:]\n",
        "      ddqi = ddq#[idx_data,:]\n",
        "      Momi = Mom#[idx_data,:]\n",
        "      Momi = tf.reshape(Momi,[Momi.shape[0],Momi.shape[1],1])\n",
        "      time1 = time.time()                           \n",
        "      loss = self.train(qi,dqi,ddqi,Momi)                \n",
        "      loss_numpy = loss.numpy()\n",
        "      loss_save.append(loss_numpy) \n",
        "      if ep%100==0:\n",
        "          time2 = time.time()\n",
        "          tt1 = time2-time1\n",
        "          tf.print(tt1,ep,loss_numpy)\n",
        "    return loss_save\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "def main():\n",
        "  #1.数据准备\n",
        "  state_roll = np.loadtxt('./f16flyingdatasets/state_roll2020-9-16.dat')\n",
        "  state_pitch = np.loadtxt('./f16flyingdatasets/state_pitch2020-9-16.dat')\n",
        "  state_yaw = np.loadtxt('./f16flyingdatasets/state_yaw2020-9-16.dat')\n",
        "\n",
        "  state = np.vstack((state_roll,state_pitch,state_yaw)) \n",
        "  state = state \n",
        "  q = state[:,0:3]\n",
        "  dq = state[:,3:6]\n",
        "  ddq = state[:,6:9]\n",
        "  mom = state[:,9:12]\n",
        "  #mom0 = tf.reshape(mom,[mom.shape[0],mom.shape[1],1])\n",
        "  #2.网络初始化\n",
        "  layers = [3]+6*[9]+[3]+[3]\n",
        "  hp = {}\n",
        "  hp[\"epochs\"] = 1\n",
        "  hp[\"tf_lr\"] = 0.01\n",
        "  hp[\"tf_b1\"] = 0.9\n",
        "  hp[\"tf_eps\"] = 0.000000001\n",
        "  hp[\"lamda\"] = 0.01\n",
        "  #hp['batchsize'] = q.shape[0]\n",
        "  vnet = vehicle_net(layers=layers,hp=hp)\n",
        "\n",
        "  #3.训练\n",
        "  losses = vnet.fit(q,dq,ddq,mom,mini_batch_size=q.shape[0])  \n",
        "  #保存结果\n",
        "  np.savetxt('./f16flyingdatasets/loss.dat',losses)\n",
        "  #path = 'save/926'\n",
        "  # vnet.model.save_model(path)\n",
        "  save_model(vnet.model, \"./f16flyingdatasets/save/\") \n",
        "  #restore_model(vnet.model,\"saved/\")\n",
        "\n",
        "\n",
        "\n",
        "def validate():\n",
        "  #1.数据准备\n",
        "  state_roll = np.loadtxt('input_data/state_roll2020-9-16.dat')\n",
        "  state_pitch = np.loadtxt('input_data/state_pitch2020-9-16.dat')\n",
        "  state_yaw = np.loadtxt('input_data/state_yaw2020-9-16.dat')\n",
        "  state = np.vstack((state_roll,state_pitch,state_yaw))\n",
        "  state = state_roll\n",
        "  q = state[:,0:3]\n",
        "  dq = state[:,3:6]\n",
        "  ddq = state[:,6:9]\n",
        "  mom = state[:,9:12]\n",
        "  mom = tf.reshape(mom,[mom.shape[0],mom.shape[1],1])\n",
        "  #恢复网络\n",
        "  hp = {}\n",
        "  hp[\"epochs\"] = 2000\n",
        "  hp[\"tf_lr\"] = 0.01\n",
        "  hp[\"tf_b1\"] = 0.9\n",
        "  hp[\"tf_eps\"] = 0.000000001\n",
        "  hp[\"lamda\"] = 0.01\n",
        "  #hp[\"batchsize\"] = 1001\n",
        "  layers = [3]+6*[9]+[3]+[3]\n",
        "  vnet = vehicle_net(layers=layers,hp=hp)\n",
        "  restore_model(vnet.model,\"saved0927/\")\n",
        "\n",
        "  t1 = time.time()\n",
        "  mom_pred = vnet.cal_inverse_dynamic(q,dq,ddq)\n",
        "  t2 = time.time()\n",
        "  print(t2-t1)\n",
        "  plt.figure()\n",
        "  loss = np.loadtxt('loss.dat')\n",
        "  plt.plot(loss)  \n",
        "  plt.figure()\n",
        "  for fig_id in range(3):\n",
        "      plt.subplot(3,1,fig_id+1)\n",
        "      plt.plot(mom_pred[:,fig_id,:])\n",
        "      plt.plot(mom[:,fig_id,:],'--')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        "  #validate()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f34feeced00a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m   \u001b[0;31m#validate()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-f34feeced00a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[0;31m# state_yaw = np.loadtxt('input_data/state_yaw2020-9-16.dat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m   \u001b[0mstate_roll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:\\work\\lagrange_net\\input_data\\state_roll2020-9-16.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m   \u001b[0mstate_pitch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:\\work\\lagrange_net\\input_data\\state_roll2020-9-16.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0mstate_yaw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:\\work\\lagrange_net\\input_data\\state_roll2020-9-16.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: upload() takes 0 positional arguments but 1 was given"
          ]
        }
      ]
    }
  ]
}